{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### LR Lecture: https://www.youtube.com/watch?v=lNHaZlZJATw&list=PLoROMvodv4rNH7qL6-efu_q2_bPuy0adh&index=4\n### Optimizers: https://www.youtube.com/playlist?list=PLKnIA16_RmvYhD5pqAeVu3j_jTjnTJIW2","metadata":{}},{"cell_type":"code","source":"from sklearn.datasets import make_regression\nimport random\nimport numpy as np","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T15:30:07.520143Z","iopub.execute_input":"2024-11-13T15:30:07.520597Z","iopub.status.idle":"2024-11-13T15:30:07.526398Z","shell.execute_reply.started":"2024-11-13T15:30:07.520556Z","shell.execute_reply":"2024-11-13T15:30:07.524990Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"X, y = make_regression(n_samples=500, n_features=5, noise=1, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T15:30:07.746595Z","iopub.execute_input":"2024-11-13T15:30:07.747090Z","iopub.status.idle":"2024-11-13T15:30:07.756502Z","shell.execute_reply.started":"2024-11-13T15:30:07.747044Z","shell.execute_reply":"2024-11-13T15:30:07.754992Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T15:30:07.952636Z","iopub.execute_input":"2024-11-13T15:30:07.953115Z","iopub.status.idle":"2024-11-13T15:30:07.962193Z","shell.execute_reply.started":"2024-11-13T15:30:07.953067Z","shell.execute_reply":"2024-11-13T15:30:07.960909Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"(500, 5)"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"ones_column=np.array([[one] for one in np.ones(X.shape[0])])\nX=np.concatenate([ones_column,X],axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T15:30:08.096354Z","iopub.execute_input":"2024-11-13T15:30:08.096813Z","iopub.status.idle":"2024-11-13T15:30:08.105288Z","shell.execute_reply.started":"2024-11-13T15:30:08.096772Z","shell.execute_reply":"2024-11-13T15:30:08.103996Z"}},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":"# 1. Gradient Descent ","metadata":{}},{"cell_type":"code","source":"thetas_1=[random.uniform(0, 1) for i in range(6)]\nlen(thetas_1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T15:11:11.022445Z","iopub.execute_input":"2024-11-11T15:11:11.023812Z","iopub.status.idle":"2024-11-11T15:11:11.031689Z","shell.execute_reply.started":"2024-11-11T15:11:11.023749Z","shell.execute_reply":"2024-11-11T15:11:11.030330Z"}},"outputs":[{"execution_count":141,"output_type":"execute_result","data":{"text/plain":"6"},"metadata":{}}],"execution_count":141},{"cell_type":"code","source":"epochs=200\n\ndef training_loop_gd(X,y,thetas,epochs):\n    for epoch in range(epochs):\n        loss=0\n        theta_grad=0\n        for i in range(X.shape[0]):\n            #Forward Pass\n            y_pred=sum([x*theta for x,theta in zip(X[i],thetas)])\n        \n            # Loss Calculation\n            \n            loss+=(y[i]-y_pred)**2\n            theta_grad+= [x*theta-y[i] for x,theta in zip(X[i],thetas)]*X[i]\n            #print(len(theta_grad))\n        \n        # Update \n        thetas=thetas-0.001*theta_grad\n        #if sum(theta_grad)<1:\n        #    thetas=[random.uniform(0, 1) for i in range(6)]\n        #print('theta_grad',theta_grad)\n        if epoch%10==0:\n            print(f'epoch: {epoch}, loss:{loss}')\n\ntraining_loop_gd(X,y,thetas_1,epochs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T15:11:11.231593Z","iopub.execute_input":"2024-11-11T15:11:11.232173Z","iopub.status.idle":"2024-11-11T15:11:12.509749Z","shell.execute_reply.started":"2024-11-11T15:11:11.232124Z","shell.execute_reply":"2024-11-11T15:11:12.508413Z"}},"outputs":[{"name":"stdout","text":"epoch: 0, loss:6454781.029208811\nepoch: 10, loss:50532.00581840638\nepoch: 20, loss:50862.24067812977\nepoch: 30, loss:50862.859761460386\nepoch: 40, loss:50862.8610202501\nepoch: 50, loss:50862.86102303466\nepoch: 60, loss:50862.86102304115\nepoch: 70, loss:50862.861023041136\nepoch: 80, loss:50862.861023041136\nepoch: 90, loss:50862.861023041136\nepoch: 100, loss:50862.861023041136\nepoch: 110, loss:50862.861023041136\nepoch: 120, loss:50862.861023041136\nepoch: 130, loss:50862.861023041136\nepoch: 140, loss:50862.861023041136\nepoch: 150, loss:50862.861023041136\nepoch: 160, loss:50862.861023041136\nepoch: 170, loss:50862.861023041136\nepoch: 180, loss:50862.861023041136\nepoch: 190, loss:50862.861023041136\n","output_type":"stream"}],"execution_count":142},{"cell_type":"markdown","source":"### GD gets Stuck in Local Minima","metadata":{}},{"cell_type":"markdown","source":"# 2. Stochastic Gradient Descent ","metadata":{}},{"cell_type":"code","source":"train_data=list(zip(X,y))\nshuffled_train_data=random.sample(train_data,len(train_data))\nX_shuffled=np.array([x for x,y in shuffled_train_data])\ny_shuffled=np.array([y for x,y in shuffled_train_data])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T15:11:12.512230Z","iopub.execute_input":"2024-11-11T15:11:12.512597Z","iopub.status.idle":"2024-11-11T15:11:12.522212Z","shell.execute_reply.started":"2024-11-11T15:11:12.512562Z","shell.execute_reply":"2024-11-11T15:11:12.520863Z"}},"outputs":[],"execution_count":143},{"cell_type":"code","source":"thetas_2=[random.uniform(0, 1) for i in range(6)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T15:11:12.523818Z","iopub.execute_input":"2024-11-11T15:11:12.524464Z","iopub.status.idle":"2024-11-11T15:11:12.535285Z","shell.execute_reply.started":"2024-11-11T15:11:12.524410Z","shell.execute_reply":"2024-11-11T15:11:12.533958Z"}},"outputs":[],"execution_count":144},{"cell_type":"code","source":"epochs=500\nbatch_size=10\nnum_iters=X.shape[0]//batch_size\nbatches=np.arange(0,X.shape[0]+batch_size,batch_size)\n\ndef training_loop_sgd(X,y,thetas,epochs,batch_size):\n    for epoch in range(epochs):\n        loss=0\n        for iter in range(num_iters):\n            # Forward Pass and Update at end of each batch\n            theta_grad=np.zeros_like(thetas)\n            for i in range(batches[iter],batches[iter+1]):\n                #Forward Pass\n                y_pred=sum([x*theta for x,theta in zip(X[i],thetas)]) \n        \n                # Loss Calculation\n                loss+= (y[i]-y_pred)**2\n                theta_grad+= -2 * (y[i] - y_pred) * X[i]\n                if i==batches[iter+1]-1:\n                    thetas=thetas-0.00001*theta_grad\n                    \n        if epoch%10==0:\n            print(f'epoch: {epoch}, loss:{loss/X_shuffled.shape[0]}')\n            \ntraining_loop_sgd(X_shuffled,y_shuffled,thetas_2,epochs,batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T15:14:22.905257Z","iopub.execute_input":"2024-11-11T15:14:22.905815Z","iopub.status.idle":"2024-11-11T15:14:25.591016Z","shell.execute_reply.started":"2024-11-11T15:14:22.905767Z","shell.execute_reply":"2024-11-11T15:14:25.589782Z"}},"outputs":[{"name":"stdout","text":"epoch: 0, loss:12879.034509586032\nepoch: 10, loss:10539.34365198201\nepoch: 20, loss:8628.605650957465\nepoch: 30, loss:7067.490047528724\nepoch: 40, loss:5791.459281456518\nepoch: 50, loss:4747.988780978844\nepoch: 60, loss:3894.3132393364594\nepoch: 70, loss:3195.5988147171943\nepoch: 80, loss:2623.460212313225\nepoch: 90, loss:2154.7571234568154\nepoch: 100, loss:1770.6170253426017\nepoch: 110, loss:1455.6414639448817\nepoch: 120, loss:1197.2611182295423\nepoch: 130, loss:985.2115509776658\nepoch: 140, loss:811.1068929807798\nepoch: 150, loss:668.0930268929251\nepoch: 160, loss:550.5653312695915\nepoch: 170, loss:453.9388728887892\nepoch: 180, loss:374.4612242948094\nepoch: 190, loss:309.05993689514884\nepoch: 200, loss:255.2182012361794\nepoch: 210, loss:210.8734425953896\nepoch: 220, loss:174.33458612606407\nepoch: 230, loss:144.21452540233102\nepoch: 240, loss:119.37497684074151\nepoch: 250, loss:98.88142882195716\nepoch: 260, loss:81.96632161392156\nepoch: 270, loss:67.99894118413106\nepoch: 280, loss:56.46079187864387\nepoch: 290, loss:46.92544204001877\nepoch: 300, loss:39.04202289613226\nepoch: 310, loss:32.521712545636035\nepoch: 320, loss:27.12666013182281\nepoch: 330, loss:22.66090563485298\nepoch: 340, loss:18.962932420575047\nepoch: 350, loss:15.899556248595731\nepoch: 360, loss:13.36090869218346\nepoch: 370, loss:11.256317154388322\nepoch: 380, loss:9.510919743728197\nepoch: 390, loss:8.06288271388629\nepoch: 400, loss:6.861112206658903\nepoch: 410, loss:5.863371666889019\nepoch: 420, loss:5.034732336762652\nepoch: 430, loss:4.346297347009409\nepoch: 440, loss:3.774150643670286\nepoch: 450, loss:3.2984907602895808\nepoch: 460, loss:2.9029166244226627\nepoch: 470, loss:2.573838465779617\nepoch: 480, loss:2.299991708929011\nepoch: 490, loss:2.0720356800653636\n","output_type":"stream"}],"execution_count":156},{"cell_type":"markdown","source":"# SGD With Momentum","metadata":{}},{"cell_type":"code","source":"train_data=list(zip(X,y))\nshuffled_train_data=random.sample(train_data,len(train_data))\nX_shuffled=np.array([x for x,y in shuffled_train_data])\ny_shuffled=np.array([y for x,y in shuffled_train_data])\nthetas_3=[random.uniform(0, 1) for i in range(6)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T15:30:19.226314Z","iopub.execute_input":"2024-11-13T15:30:19.226775Z","iopub.status.idle":"2024-11-13T15:30:19.237443Z","shell.execute_reply.started":"2024-11-13T15:30:19.226731Z","shell.execute_reply":"2024-11-13T15:30:19.236173Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"epochs=500\nbatch_size=10\nnum_iters=X.shape[0]//batch_size\nbatches=np.arange(0,X.shape[0]+batch_size,batch_size)\nbeta=0.9\n\ndef training_loop_sgd_momentum(X,y,thetas,epochs,batch_size,beta):\n    momentum=np.zeros_like(thetas)\n    for epoch in range(epochs):\n        loss=0\n        for iter in range(num_iters):\n            theta_grad= np.zeros_like(thetas)\n            # Forward Pass and Update at end of each batch\n            for i in range(batches[iter],batches[iter+1]):\n                #Forward Pass\n                y_pred= np.dot(X[i],thetas) \n        \n                # Loss Calculation\n                loss+= (y[i]-y_pred)**2\n                theta_grad+= -2 * (y[i] - y_pred) * X[i]\n\n            theta_grad/=batch_size\n            momentum = beta * momentum + theta_grad\n            thetas=thetas-0.00001*(momentum)\n        if epoch%10==0:\n            print(f'epoch: {epoch}, loss:{loss/X_shuffled.shape[0]}')\n            \n            \ntraining_loop_sgd_momentum(X_shuffled,y_shuffled,thetas_3,epochs,batch_size,beta)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T15:30:20.357628Z","iopub.execute_input":"2024-11-13T15:30:20.358137Z","iopub.status.idle":"2024-11-13T15:30:22.670872Z","shell.execute_reply.started":"2024-11-13T15:30:20.358091Z","shell.execute_reply":"2024-11-13T15:30:22.669658Z"}},"outputs":[{"name":"stdout","text":"epoch: 0, loss:12863.408281760985\nepoch: 10, loss:10528.592747061504\nepoch: 20, loss:8614.366618998034\nepoch: 30, loss:7051.386326948678\nepoch: 40, loss:5774.6351928239455\nepoch: 50, loss:4731.231571541081\nepoch: 60, loss:3878.1461792150185\nepoch: 70, loss:3180.35193661421\nepoch: 80, loss:2609.3238234568717\nepoch: 90, loss:2141.8220746772854\nepoch: 100, loss:1758.9048287547296\nepoch: 110, loss:1445.1266535864497\nepoch: 120, loss:1187.8877046283878\nepoch: 130, loss:976.9049975907548\nepoch: 140, loss:803.7827135393945\nepoch: 150, loss:661.6628473274831\nepoch: 160, loss:544.9410619437009\nepoch: 170, loss:449.03548370619893\nepoch: 180, loss:370.198496957521\nepoch: 190, loss:305.3634774435578\nepoch: 200, loss:252.01992593923998\nepoch: 210, loss:208.1116965525077\nepoch: 220, loss:171.9540129044118\nepoch: 230, loss:142.16577478761386\nepoch: 240, loss:117.61431408850237\nepoch: 250, loss:97.37029091952412\nepoch: 260, loss:80.6708526494014\nepoch: 270, loss:66.88952892102512\nepoch: 280, loss:55.51162024248\nepoch: 290, loss:46.114068811071554\nepoch: 300, loss:38.348987987699864\nepoch: 310, loss:31.93017945989095\nepoch: 320, loss:26.622091240724153\nepoch: 330, loss:22.230770615109243\nepoch: 340, loss:18.59644831375832\nepoch: 350, loss:15.587457095019849\nepoch: 360, loss:13.095242405449396\nepoch: 370, loss:11.030267191685965\nepoch: 380, loss:9.318649132102488\nepoch: 390, loss:7.899398075720944\nepoch: 400, loss:6.72214555987164\nepoch: 410, loss:5.745277936168402\nepoch: 420, loss:4.934400686767061\nepoch: 430, loss:4.261074626549345\nepoch: 440, loss:3.7017754045428415\nepoch: 450, loss:3.2370364810429306\nepoch: 460, loss:2.8507429251573035\nepoch: 470, loss:2.5295492436563465\nepoch: 480, loss:2.262399254715636\nepoch: 490, loss:2.0401299538917184\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"train_data=list(zip(X,y))\nshuffled_train_data=random.sample(train_data,len(train_data))\nX_shuffled=np.array([x for x,y in shuffled_train_data])\ny_shuffled=np.array([y for x,y in shuffled_train_data])\nthetas_4=[random.uniform(0, 1) for i in range(6)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T15:30:25.140683Z","iopub.execute_input":"2024-11-13T15:30:25.141185Z","iopub.status.idle":"2024-11-13T15:30:25.151397Z","shell.execute_reply.started":"2024-11-13T15:30:25.141140Z","shell.execute_reply":"2024-11-13T15:30:25.150279Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"epochs=500\nbatch_size=10\nnum_iters=X.shape[0]//batch_size\nbatches=np.arange(0,X.shape[0]+batch_size,batch_size)\nbeta=0.6\n\ndef training_loop_nag(X,y,thetas,epochs,batch_size,beta):StopIteration\n    momentum=np.zeros_like(thetas)\n    for epoch in range(epochs):\n        loss=0\n        for iter in range(num_iters):\n            theta_grad= np.zeros_like(thetas)\n            thetas_lookahead=thetas- (beta*momentum) #calculate look ahead point using momentum\n            \n            # Forward Pass and Update at end of each batch\n            for i in range(batches[iter],batches[iter+1]):\n                #Forward Pass\n                y_pred= np.dot(X[i],thetas_lookahead) \n        \n                # Loss Calculation\n                loss+= (y[i]-y_pred)**2\n                theta_grad+= -2 * (y[i] - y_pred) * X[i] \n\n            theta_grad/=batch_size # calculate gradient at look ahead pt\n            momentum = beta * momentum + theta_grad # add gradient at look ahead pt to the momentum\n            thetas = thetas -  0.001 * momentum #  update theta\n\n        if epoch%10==0:\n            print(f'epoch: {epoch}, loss:{loss/X_shuffled.shape[0]}')\n            \n            \ntraining_loop_nag(X_shuffled,y_shuffled,thetas_4,epochs,batch_size,beta)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T15:31:29.640373Z","iopub.execute_input":"2024-11-13T15:31:29.641423Z","iopub.status.idle":"2024-11-13T15:31:32.026275Z","shell.execute_reply.started":"2024-11-13T15:31:29.641370Z","shell.execute_reply":"2024-11-13T15:31:32.025062Z"}},"outputs":[{"name":"stdout","text":"epoch: 0, loss:3549.209343848277\nepoch: 10, loss:910.5630230064288\nepoch: 20, loss:264.00549127562863\nepoch: 30, loss:78.44413764737746\nepoch: 40, loss:25.63786039002453\nepoch: 50, loss:10.871534249394601\nepoch: 60, loss:6.891953020212577\nepoch: 70, loss:5.905720219361547\nepoch: 80, loss:5.712684178280186\nepoch: 90, loss:5.7080819591217535\nepoch: 100, loss:5.735074655000115\nepoch: 110, loss:5.7584897112337945\nepoch: 120, loss:5.773842760706607\nepoch: 130, loss:5.7829925047565816\nepoch: 140, loss:5.78821983012024\nepoch: 150, loss:5.791144695570138\nepoch: 160, loss:5.792763474025915\nepoch: 170, loss:5.793654021326234\nepoch: 180, loss:5.794142241571716\nepoch: 190, loss:5.794409325544679\nepoch: 200, loss:5.794555230600387\nepoch: 210, loss:5.794634857610893\nepoch: 220, loss:5.794678280685037\nepoch: 230, loss:5.7947019460478195\nepoch: 240, loss:5.79471483681142\nepoch: 250, loss:5.794721855324845\nepoch: 260, loss:5.794725675064499\nepoch: 270, loss:5.794727753140732\nepoch: 280, loss:5.794728883306962\nepoch: 290, loss:5.794729497760647\nepoch: 300, loss:5.7947298317344575\nepoch: 310, loss:5.794730013211765\nepoch: 320, loss:5.794730111800831\nepoch: 330, loss:5.794730165348253\nepoch: 340, loss:5.794730194426242\nepoch: 350, loss:5.794730210213406\nepoch: 360, loss:5.79473021878322\nepoch: 370, loss:5.794730223434626\nepoch: 380, loss:5.794730225958662\nepoch: 390, loss:5.794730227328403\nepoch: 400, loss:5.794730228071378\nepoch: 410, loss:5.794730228474562\nepoch: 420, loss:5.794730228693389\nepoch: 430, loss:5.79473022881189\nepoch: 440, loss:5.794730228876095\nepoch: 450, loss:5.794730228911024\nepoch: 460, loss:5.7947302289298905\nepoch: 470, loss:5.794730228940217\nepoch: 480, loss:5.794730228945651\nepoch: 490, loss:5.794730228948744\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"train_data=list(zip(X,y))\nshuffled_train_data=random.sample(train_data,len(train_data))\nX_shuffled=np.array([x for x,y in shuffled_train_data])\ny_shuffled=np.array([y for x,y in shuffled_train_data])\nthetas_5=[random.uniform(0, 1) for i in range(6)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T15:45:58.409247Z","iopub.execute_input":"2024-11-13T15:45:58.410600Z","iopub.status.idle":"2024-11-13T15:45:58.423126Z","shell.execute_reply.started":"2024-11-13T15:45:58.410522Z","shell.execute_reply":"2024-11-13T15:45:58.421635Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"# adagrad faces issues with convergence\nepochs=500\nbatch_size=10\nnum_iters=X.shape[0]//batch_size\nbatches=np.arange(0,X.shape[0]+batch_size,batch_size)\n\ndef training_loop_adagrad(X,y,thetas,epochs,batch_size):\n    square_grad=np.zeros_like(thetas)\n    epsilon=np.zeros_like(thetas)+ 1e-8\n    for epoch in range(epochs):\n        loss=0\n        for iter in range(num_iters):\n            theta_grad= np.zeros_like(thetas)\n            # Forward Pass and Update at end of each batch\n            for i in range(batches[iter],batches[iter+1]):\n                #Forward Pass\n                y_pred= np.dot(X[i],thetas) \n        \n                # Loss Calculation\n                loss+= (y[i]-y_pred)**2\n                theta_grad+= -2 * (y[i] - y_pred) * X[i] \n\n            theta_grad/=batch_size\n            square_grad =  square_grad + np.power(theta_grad,2) \n            thetas = thetas -  0.01 * np.divide(theta_grad, np.sqrt(square_grad+epsilon)) #  update theta\n\n        if epoch%10==0:\n            print(f'epoch: {epoch}, loss:{loss/X_shuffled.shape[0]}')\n            \n            \ntraining_loop_adagrad(X_shuffled,y_shuffled,thetas_5,epochs,batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T15:52:02.854412Z","iopub.execute_input":"2024-11-13T15:52:02.854914Z","iopub.status.idle":"2024-11-13T15:52:05.238736Z","shell.execute_reply.started":"2024-11-13T15:52:02.854866Z","shell.execute_reply":"2024-11-13T15:52:05.237386Z"}},"outputs":[{"name":"stdout","text":"epoch: 0, loss:13003.9969163946\nepoch: 10, loss:12883.386694799785\nepoch: 20, loss:12823.201318539366\nepoch: 30, loss:12776.826539413702\nepoch: 40, loss:12737.713715196096\nepoch: 50, loss:12703.274047453715\nepoch: 60, loss:12672.167158589536\nepoch: 70, loss:12643.592281137144\nepoch: 80, loss:12617.025687998326\nepoch: 90, loss:12592.102602955447\nepoch: 100, loss:12568.556886575545\nepoch: 110, loss:12546.18730060043\nepoch: 120, loss:12524.837299838942\nepoch: 130, loss:12504.382259212438\nepoch: 140, loss:12484.72104295509\nepoch: 150, loss:12465.770237524846\nepoch: 160, loss:12447.460086573154\nepoch: 170, loss:12429.731551527131\nepoch: 180, loss:12412.534138770008\nepoch: 190, loss:12395.8242623632\nepoch: 200, loss:12379.563989306866\nepoch: 210, loss:12363.72006346041\nepoch: 220, loss:12348.263136021935\nepoch: 230, loss:12333.167151527045\nepoch: 240, loss:12318.408852595234\nepoch: 250, loss:12303.967376505641\nepoch: 260, loss:12289.823923611068\nepoch: 270, loss:12275.961482547824\nepoch: 280, loss:12262.364600785422\nepoch: 290, loss:12249.019191694451\nepoch: 300, loss:12235.912371271215\nepoch: 310, loss:12223.032319130143\nepoch: 320, loss:12210.368159496362\nepoch: 330, loss:12197.909858789693\nepoch: 340, loss:12185.648137057702\nepoch: 350, loss:12173.574391035541\nepoch: 360, loss:12161.680627019694\nepoch: 370, loss:12149.95940206771\nepoch: 380, loss:12138.403772295502\nepoch: 390, loss:12127.007247252437\nepoch: 400, loss:12115.763749523014\nepoch: 410, loss:12104.667578841623\nepoch: 420, loss:12093.713380118945\nepoch: 430, loss:12082.896114871175\nepoch: 440, loss:12072.21103561963\nepoch: 450, loss:12061.653662891897\nepoch: 460, loss:12051.219764508418\nepoch: 470, loss:12040.905336882846\nepoch: 480, loss:12030.70658810228\nepoch: 490, loss:12020.619922583988\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}